## 荣誉准则
1. 在完成本次实验的过程（含此前学习的过程）中，我曾分别与 以下各位 就（与本次实验相关的）以下方面做过交流，还在代码中对应的位置以注释形式记录了具体的交流对象及内容：和GPT讨论过一些语法类问题，请教微信群友的问题并未被群友解决，最终自行解决。

2. 此外，我也参考了 以下资料 ，还在代码中对应的位置以注释形式记录了具体的参考来源及内容：代码思路部分除官方文档外未参考任何rcore相关资料，语法部分参考了若干资料。

3. 我独立完成了本次实验除以上方面之外的所有工作，包括代码与文档。 我清楚地知道，从以上方面获得的信息在一定程度上降低了实验难度，可能会影响起评分。

4. 我从未使用过他人的代码，不管是原封不动地复制，还是经过了某些等价转换。 我未曾也不会向他人（含此后各届同学）复制或公开我的实验代码，我有义务妥善保管好它们。 我提交至本实验的评测系统的代码，均无意于破坏或妨碍任何计算机系统的正常运转。 我清楚地知道，以上情况均为本课程纪律所禁止，若违反，对应的实验成绩将按“-100”分计。

## 总结
1.原则：先理清思路，再研究细节；先分析问题，再解决问题；注意每章的代码导读

2.整体思路：回顾已有框架功能--分析旧框架问题--引入新功能（--引入新问题）

之前的章节我们实现了特权级切换和任务切换，但所有变量的都是静态分配的，也就是应用程序运行前都已经确定好，我们这章的任务就是引入动态内存（即堆）分配，并使现存功能适配。

3.具体来说(硬件+软件)：

RISC-V64架构中提供的硬件机制

* 页表基址寄存器：satp
    * MODE域：使能页表—MODE=8
    * ASID域
    * PPN字段：根页表物理地址
* （虚拟/物理）地址格式与组成
* SV39多级页表
* MMU及TLB

框架中提供的软件机制

首先需要使操作系统内核支持动态内存分配，因此需要引入初始化堆、分配/释放内存块的函数接口、连续内存分配算法。具体的做法见：
`os/src/mm`（注意下列功能的前后递进逻辑关系）
* `/heap_allocator.rs`内核的连续内存分配功能
	* 把空闲物理内存按照堆进行动态连续内存管理
	* 分页、多级分页、虚拟多级分页的基础
* `/frame_allocator.rs`：物理页帧管理
	* 将剩下的空闲内存以单个物理页帧为单位管理起来
	* 物理页里存的可以是页表，也可以是代码/数据
	* 物理页帧管理器
	    * 两种分配方式：栈 recycled /之前从未分配过的物理页号区间 [ current , end ) 
	    * 全局实例 FRAME_ALLOCATOR，
	    * 公开的分配/回收物理页帧接口
	        * 分配：frame_alloc()，返回值是Option<FrameTracker>
	        * 回收：frame_dealloc()，参数是PhysPageNum
	    * FrameTracker：
	        * 借用了RAII的思想，将一个物理页帧的生命周期绑定到一个 FrameTracker 变量上
	        * 当一个 FrameTracker 生命周期结束被编译器回收的时候，我们需要将它控制的物理页帧回收到 FRAME_ALLOCATOR 中
* `/address.rs`：地址相关数据结构和地址转换函数
	* 物理/虚拟地址、物理/虚拟页号（后面的分配/回收操作基本都是以一个页为单位进行的，因此会用到PPN/VPN）
* `/page_table.rs`：页表/页表项相关数据结构及函数
	* 注意：内核/应用页表 
	* 以节点为单位进行管理
	    * root_ppn：根节点的物理页号（页表的唯一区分标志）
	    * frames：以FrameTracker的形式保存了页表所有的节点（包括根节点）所在的物理页帧，这些FrameTracker的生命周期被绑定到PageTable下
	* 只有内核才会才能直接访问物理地址（这句话其实容易误导读者，实际上内核也需要通过虚拟地址这一步，只是内核的虚拟地址和物理地址采用了恒等映射，具体的映射方式表示在下一节的MapType中），而访问给定PhysPageNum的物理页帧的方式有get_pte_array、get_bytes_array、get_mut三种
	* 页表项pte
	    * 描述虚实地址映射关系
	    * 页表项标志位
	* 类似 MMU 操作的手动查页表的方法：只通过root_ppn，而不涉及控制FrameTracker生命
* `/memory_set.rs`：
	* 进一步抽象出更高层次的管理对象--地址空间MemorySet、逻辑段MapArea，同样采取RAII风格，将物理页帧FrameTracker的生命（和PageTable进而）和MemorySet绑定
	* 注意：内核/应用地址空间实现方式和Linux的区别，以及只有低256G及高256G有用
	* 手册5.6.3内核地址空间：new_kernel()及全局静态实例KERNEL_SPACE
	    * 开启分页后，内核代码的访存地址也是虚拟地址
	    * 高256G：跳板放在最高的一个虚拟页面中，接下来是从高到低放置每个应用的内核栈，相邻两个内核栈之间会预留一个保护页面 (Guard Page) ，它是内核地址空间中的空洞
	    * 低256G：内核的.text/.rodata/.data/.bss四个逻辑段（恒等映射到物理内存）以及一个恒等映射到内核数据段之外的可用物理页帧的逻辑段
	* 手册5.6.4应用地址空间：from_elf()
	    * 高256G：最高页是跳板，次高页是Trap上下文
	    * 低256G：应用的的.text/.rodata/.data/.bss四个逻辑段以及用户栈
	* 内核获取应用数据：通过查询应用的页表，来把应用的虚地址转换为物理地址，内核直接访问这个地址（注：内核自身的虚实映射是恒等映射），from_token可以用来手动查表，只是利用了root_ppn，并不控制任何资源的生命
    * 核心函数分析（围绕它们展开研究ms和ma的所有接口以及小变量（指为了方便创造出来的变量，如VPNRange，MapPermission））
	    * insert_framed_area函数分析：
	    * ms.push：push调用了ma.map，为ma.vpn_range范围内的所有vpn（通过map_one）分配了一个物理页
	    * ma.map_one
	    * ma.map
	    * new_kernel和from_elf（对应手册上边5.6.3和5.6.4理论内容）
    * 地址空间的切换：借助跳板并修改satp
* `/mod.rs`：mm子模块初始化方法init()
	* mm子系统初始化后即启动了分页模式

4.问题分析：
* 注意：
    * 一定要先分析样例！
    * vpn--ppn--pte
* lab1里的两个系统调用：手动查表，按byte拷贝
* sys_mmap和sys_munmap：手册里描述的有点模糊，实际上通过阅读样例可知，该系统调用的功能就是以页为单位进行分配/回收，而且不会出现复杂的情况（比如跨越area，部分可回收部分不可…），关键点就是边界条件、port以及每次分配/回收都要同时操作pagetable和areas，需要注意的点就是接口的设计问题（没有暴露出来的内容，需要用接口传参数进去在本地处理）

## 体会
* 测试样例感觉过于简单
* dbg配置过于复杂，希望能参考pintos进行优化